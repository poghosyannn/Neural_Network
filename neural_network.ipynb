{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "X_diab, y_diab = load_diabetes(return_X_y=True) # returns diabetes data shapes: (442, 10) and (442,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X_reg, y_reg = make_regression(n_samples=60, n_features=10, noise=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(\n",
    "            self, \n",
    "            units, \n",
    "            *, \n",
    "            input_layer: bool = False,\n",
    "            activation: str = \"linear\",\n",
    "            use_bias: bool = True):\n",
    "        \"\"\"\n",
    "        Initialize a neural network layer.\n",
    "\n",
    "        Args:\n",
    "            units (int): Count of neurons in the layer.\n",
    "            input_layer (bool, optional): Whether the layer is an input layer. Defaults to False.\n",
    "            activation (str, optional): Activation function for the layer. Can be \"linear\", \"relu\", or \"sigmoid\". Defaults to \"linear\".\n",
    "            use_bias (bool, optional): Whether to use bias in the layer. Defaults to True.\n",
    "        \"\"\"\n",
    "            \n",
    "        \n",
    "        self.units = units\n",
    "        self.input_layer = input_layer\n",
    "        self.activation = activation\n",
    "        self.use_bias = use_bias\n",
    "\n",
    "        self._input = None\n",
    "        self._output = None\n",
    "\n",
    "        self.w = None # Weights matrix\n",
    "        self._weight_gradient = None # Weight derivative matrix\n",
    "        self._bias_gradient = None # Bias derivative vector\n",
    "\n",
    "    def activationFunction(self, z):\n",
    "        \"\"\"\n",
    "        Apply the activation function to the given input.\n",
    "\n",
    "        Args:\n",
    "            z (numpy.ndarray): Input to the activation function.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Output after applying the activation function.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.activation == \"linear\":\n",
    "            return z\n",
    "\n",
    "        if self.activation == \"relu\":\n",
    "            return np.maximum(z, np.zeros(z.shape))\n",
    "\n",
    "        if self.activation == \"sigmoid\":\n",
    "            return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def _weightInit(self, input_size):\n",
    "        \"\"\"\n",
    "        Initialize the weights matrix based on the input size.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): Size of the input.\n",
    "\n",
    "        Notes:\n",
    "            Only executed for layers other than the input layer.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.input_layer:\n",
    "            return # input_layer doesn't need weights\n",
    "\n",
    "        self.w = np.random.normal(loc = 0, scale = 1 / input_size, size=(input_size, self.units)) # loc -> mean, scale -> variance\n",
    "        self.bias = np.zeros((1, self.units))\n",
    "\n",
    "\n",
    "    def _activationDerivative(self):\n",
    "        \"\"\"\n",
    "        Compute the derivative of the activation function.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Derivative of the activation function.\n",
    "\n",
    "        Notes:\n",
    "            Only supports the \"linear\", \"relu\", and \"sigmoid\" activation functions.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.activation == \"linear\":\n",
    "            return 1\n",
    "\n",
    "        if self.activation == \"relu\":\n",
    "            return (self._output > 0) * 1\n",
    "\n",
    "        if self.activation == \"sigmoid\":\n",
    "            return self._output * (1 - self._output)\n",
    "\n",
    "    def _setGrad(self, grad):\n",
    "        \"\"\"\n",
    "        Calculate the gradients of weights and bias for backpropagation.\n",
    "\n",
    "        Args:\n",
    "            grad (numpy.ndarray): Gradient from the previous layer.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Gradient to be passed to the previous layer.\n",
    "\n",
    "        Notes:\n",
    "            Only executed for layers other than the input layer.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.input_layer:\n",
    "            return\n",
    "        \n",
    "        grad = grad * self._activationDerivative()\n",
    "        self._weight_gradient = self._input.T @ grad\n",
    "\n",
    "        if self.use_bias:\n",
    "            self._bias_gradient = grad.sum(axis=0, keepdims=True)\n",
    "\n",
    "        return grad @ self.w.T\n",
    "    \n",
    "    def _updateGrad(self, learning_rate):\n",
    "        \"\"\"\n",
    "        Update the weights and bias based on the computed gradients.\n",
    "\n",
    "        Args:\n",
    "            learning_rate (float): Learning rate for gradient descent.\n",
    "\n",
    "        Notes:\n",
    "            Only executed for layers other than the input layer.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.w -= learning_rate * self._weight_gradient\n",
    "        if self.use_bias:\n",
    "            self.bias -= learning_rate * self._bias_gradient\n",
    "\n",
    "    def call(self, X):\n",
    "        \"\"\"\n",
    "        Perform a forward pass through the layer.\n",
    "\n",
    "        Args:\n",
    "            X (numpy.ndarray): Input to the layer.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Output of the layer after applying the activation function.\n",
    "        \"\"\"\n",
    "        if self.input_layer:\n",
    "            return X\n",
    "        \n",
    "        self._input = X\n",
    "        self._output = self.activationFunction(X @ self.w + self.bias)\n",
    "\n",
    "        return self._output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeauralNetwork:\n",
    "    def __init__(\n",
    "            self, \n",
    "            layers: list, \n",
    "            loss_function: str = \"mse\", \n",
    "            learning_rate = 0.01, \n",
    "            max_iter=1000,\n",
    "            verbose: bool = False):\n",
    "        \"\"\"\n",
    "        Initialize a neural network.\n",
    "\n",
    "        Args:\n",
    "            layers (list): List of Layer objects defining the network architecture. \n",
    "            loss_function (str, optional): Loss function to use. Defaults to \"mse\".\n",
    "            learning_rate (float, optional): Learning rate for gradient descent. Defaults to 0.01.\n",
    "            max_iter (int, optional): Maximum number of iterations for training. Defaults to 1000.\n",
    "            verbose (bool, optional): Whether to display training progress. Defaults to False.\n",
    "        \"\"\"\n",
    "\n",
    "        self.layers = layers\n",
    "        self.loss_function = loss_function\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # Weights initializing:\n",
    "        for i in range(1, len(self.layers)):\n",
    "            self.layers[i]._weightInit(self.layers[i - 1].units)\n",
    "\n",
    "    def lossFunction(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Compute the loss between the true values and predicted values.\n",
    "\n",
    "        Args:\n",
    "            y_true (numpy.ndarray): True values.\n",
    "            y_pred (numpy.ndarray): Predicted values.\n",
    "\n",
    "        Returns:\n",
    "            float: Loss value.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.loss_function == \"mse\":\n",
    "            return 0.5 * np.mean(np.linalg.norm(y_pred - y_true, axis=1)**2)\n",
    "\n",
    "        # Can be add\n",
    "\n",
    "    def _lossFunctionDerivative(self, y_pred, y_true):\n",
    "        \"\"\"\n",
    "        Compute the derivative of the loss function.\n",
    "\n",
    "        Args:\n",
    "            y_pred (numpy.ndarray): Predicted values.\n",
    "            y_true (numpy.ndarray): True values.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Derivative of the loss function.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.loss_function == \"mse\":\n",
    "            return 1 / len(y_pred) * (y_pred - y_true)\n",
    "\n",
    "        # Can be add\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the neural network on the given input-output pairs.\n",
    "\n",
    "        Args:\n",
    "            X (numpy.ndarray): Input data.\n",
    "            y (numpy.ndarray): Output data.\n",
    "\n",
    "        Notes:\n",
    "            Reshapes X and y to match the expected input shapes of the network.\n",
    "        \"\"\"\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            pred = self.forward(X)\n",
    "\n",
    "            if self.verbose:\n",
    "                process_percent = int(_ / self.max_iter * 20)\n",
    "                print(f\"\\r {_}/{self.max_iter}: [{process_percent * '=' + '>' + (20 - process_percent) * '-'}] - loss: {self.lossFunction(y, pred)}\", end=\"\")\n",
    "            self.backward(pred, y)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"\\r {self.max_iter}/{self.max_iter}: [{21 * '='}] - loss: {self.lossFunction(y, pred)}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Perform predictions using the trained neural network.\n",
    "\n",
    "        Args:\n",
    "            X (numpy.ndarray): Input data.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Predicted output data.\n",
    "        \"\"\"\n",
    "\n",
    "        return self.forward(X)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Perform a forward pass through the network.\n",
    "\n",
    "        Args:\n",
    "            X (numpy.ndarray): Input data.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray\n",
    "        \"\"\"\n",
    "\n",
    "        X_ = np.copy(X)\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            X_ = layer.call(X_)\n",
    "        return X_\n",
    "\n",
    "    def backward(self, y_pred, y_true):\n",
    "        \"\"\"\n",
    "        Perform backpropagation to update the weights of the network.\n",
    "\n",
    "        Args:\n",
    "            y_pred (numpy.ndarray): Predicted values.\n",
    "            y_true (numpy.ndarray): True values.\n",
    "        \"\"\"\n",
    "        \n",
    "        gradient = self._lossFunctionDerivative(y_pred, y_true)\n",
    "\n",
    "        for i in range(len(self.layers) - 1, 0, -1):\n",
    "            gradient = self.layers[i]._setGrad(gradient)\n",
    "            self.layers[i]._updateGrad(self.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 178828/1000000: [===>-----------------] - loss: 9.234760571854228e-233"
     ]
    }
   ],
   "source": [
    "nn = NeauralNetwork(layers=[\n",
    "        Layer(units=10, input_layer=True),\n",
    "        Layer(units=40, activation=\"sigmoid\"),\n",
    "        Layer(units=40, activation=\"relu\"),\n",
    "        Layer(units=1),\n",
    "    ],\n",
    "    loss_function = \"mse\",\n",
    "    learning_rate=0.01, \n",
    "    max_iter=1000000,\n",
    "    verbose=True,\n",
    ")\n",
    "y_reg = y_reg.reshape(-1, 1)\n",
    "nn.fit(X_reg, y_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.94112320e+01],\n",
       "       [ 2.60890220e+01],\n",
       "       [ 1.76662169e+01],\n",
       "       [ 3.04361861e+01],\n",
       "       [ 3.35693160e+01],\n",
       "       [-5.84548605e-03],\n",
       "       [ 1.00292529e+01],\n",
       "       [ 3.55764771e+01],\n",
       "       [ 1.25974651e+01],\n",
       "       [ 2.83941351e+01],\n",
       "       [-2.43563388e+01],\n",
       "       [ 1.40223836e+01],\n",
       "       [ 2.47929642e+01],\n",
       "       [ 1.69523109e+01],\n",
       "       [ 3.14796441e+01],\n",
       "       [ 4.37011468e+01],\n",
       "       [ 3.10544243e+01],\n",
       "       [ 3.26852356e+01],\n",
       "       [ 2.30063293e+01],\n",
       "       [ 3.10619217e+01],\n",
       "       [ 1.80073843e+01],\n",
       "       [ 4.56017618e+00],\n",
       "       [ 1.65822936e+01],\n",
       "       [ 2.64127381e+01],\n",
       "       [ 2.39877265e+01],\n",
       "       [ 1.79053927e+01],\n",
       "       [ 7.17964432e+00],\n",
       "       [ 8.45320286e+00],\n",
       "       [ 3.46334532e+01],\n",
       "       [ 1.33801330e+01],\n",
       "       [ 1.66441408e+01],\n",
       "       [ 1.57704970e+01],\n",
       "       [ 2.75066056e+01],\n",
       "       [ 8.72376865e+00],\n",
       "       [ 9.46189154e+00],\n",
       "       [ 1.49000735e+01],\n",
       "       [ 3.78542805e+01],\n",
       "       [ 1.53966673e+01],\n",
       "       [ 4.63723405e+01],\n",
       "       [ 9.85540078e+00],\n",
       "       [ 1.48983539e+01],\n",
       "       [ 7.10988002e+00],\n",
       "       [ 1.34370093e+01],\n",
       "       [ 4.95261025e+00],\n",
       "       [ 2.68134091e+01],\n",
       "       [ 2.05949632e+01],\n",
       "       [ 2.39178827e+01],\n",
       "       [-6.68368229e+01],\n",
       "       [ 1.20199932e+01],\n",
       "       [ 1.60961039e+01],\n",
       "       [ 1.70929063e+01],\n",
       "       [ 1.70724774e+01],\n",
       "       [ 2.49802579e+01],\n",
       "       [ 1.86709411e+01],\n",
       "       [ 1.75824158e+01],\n",
       "       [ 6.13247290e+00],\n",
       "       [ 2.56464412e+01],\n",
       "       [ 1.54649331e+01],\n",
       "       [ 2.57981755e+01],\n",
       "       [ 2.48593188e+01],\n",
       "       [ 1.10626372e+01],\n",
       "       [ 6.23284622e+00],\n",
       "       [ 4.70419731e+00],\n",
       "       [ 1.46973024e+01],\n",
       "       [ 4.41954770e+00],\n",
       "       [ 1.77847672e+01],\n",
       "       [ 7.85759723e+00],\n",
       "       [ 1.13319041e+01],\n",
       "       [ 6.66432896e+00],\n",
       "       [ 1.10690170e+01],\n",
       "       [ 6.20231800e+00],\n",
       "       [ 3.42942849e+01],\n",
       "       [ 3.76192903e+01],\n",
       "       [ 1.86610144e+01],\n",
       "       [ 1.62872126e+01],\n",
       "       [ 7.27398040e+00],\n",
       "       [ 4.23167530e+00],\n",
       "       [ 1.18356576e+01],\n",
       "       [-3.70635773e+01],\n",
       "       [ 1.88943155e+01],\n",
       "       [ 4.25994997e+01],\n",
       "       [ 1.19155426e+01],\n",
       "       [ 2.42094940e+01],\n",
       "       [ 2.59986311e+01],\n",
       "       [ 2.97045892e+00],\n",
       "       [ 3.61665165e+01],\n",
       "       [ 1.13367578e+01],\n",
       "       [ 4.07160109e+01],\n",
       "       [-8.89681976e-01],\n",
       "       [ 9.58886815e+00],\n",
       "       [ 5.99898683e+00],\n",
       "       [ 3.26902740e+01],\n",
       "       [ 2.84308699e+01],\n",
       "       [ 2.00231089e+01],\n",
       "       [ 2.95548947e+01],\n",
       "       [-8.85771369e+00],\n",
       "       [ 2.25363152e+01],\n",
       "       [ 1.93745828e+01],\n",
       "       [ 2.06692034e+01],\n",
       "       [ 5.47476892e+01],\n",
       "       [ 3.32945194e+01],\n",
       "       [ 1.19986641e+01],\n",
       "       [ 1.98017484e+01],\n",
       "       [ 3.17510456e+01],\n",
       "       [ 2.38161715e+01],\n",
       "       [ 5.26965097e+00],\n",
       "       [-3.26772879e+01],\n",
       "       [ 1.95143438e+01],\n",
       "       [ 1.20310550e+01],\n",
       "       [ 6.81118357e+00],\n",
       "       [ 7.34090634e-01],\n",
       "       [ 2.68723852e+01],\n",
       "       [ 1.67242198e+01],\n",
       "       [ 1.90238717e+01],\n",
       "       [ 4.11251749e+01],\n",
       "       [ 2.74827485e+01],\n",
       "       [ 3.25493371e+01],\n",
       "       [ 2.92031712e+01],\n",
       "       [ 1.09998617e+01],\n",
       "       [ 1.47656352e+01],\n",
       "       [ 1.89840595e+01],\n",
       "       [ 3.16656491e+01],\n",
       "       [ 3.38419790e+01],\n",
       "       [ 4.48469144e+01],\n",
       "       [ 1.81533373e+01],\n",
       "       [ 1.25171221e+01],\n",
       "       [ 8.42794910e+00],\n",
       "       [ 3.04911711e+01],\n",
       "       [ 1.93539362e+01],\n",
       "       [ 1.42005480e+01],\n",
       "       [ 2.64344585e+01],\n",
       "       [-3.43354055e+01],\n",
       "       [ 1.24616389e+01],\n",
       "       [ 5.01155270e+00],\n",
       "       [ 2.10007433e+01],\n",
       "       [ 1.26630038e+01],\n",
       "       [ 7.81715830e+00],\n",
       "       [ 3.65856290e+01],\n",
       "       [ 2.82360278e+01],\n",
       "       [ 3.26958373e+01],\n",
       "       [ 1.27120162e+01],\n",
       "       [ 1.63534429e+01],\n",
       "       [ 3.16785942e+01],\n",
       "       [ 2.19700986e+01],\n",
       "       [ 2.22902854e+01],\n",
       "       [ 3.48869500e+01],\n",
       "       [ 1.90432674e+01],\n",
       "       [ 2.22723710e+01],\n",
       "       [ 1.19443417e+01],\n",
       "       [ 1.71678082e+01],\n",
       "       [ 2.56551922e+01],\n",
       "       [ 1.86465648e+01],\n",
       "       [ 2.27241954e+01],\n",
       "       [ 1.37315175e+01],\n",
       "       [ 2.08637149e+01],\n",
       "       [ 3.47691792e+01],\n",
       "       [ 2.37101270e+01],\n",
       "       [ 1.15399019e+01],\n",
       "       [ 1.17596002e+01],\n",
       "       [ 4.40504579e+01],\n",
       "       [-1.93036126e+00],\n",
       "       [ 4.56099414e+01],\n",
       "       [ 1.12082748e+01],\n",
       "       [ 2.34340270e+01],\n",
       "       [ 2.87766372e+01],\n",
       "       [ 1.08806928e+01],\n",
       "       [ 6.06456111e+00],\n",
       "       [ 3.22458761e+01],\n",
       "       [ 2.69246678e+01],\n",
       "       [ 4.18689068e+01],\n",
       "       [ 4.59092389e+00],\n",
       "       [-8.19656204e+00],\n",
       "       [ 2.80479366e+01],\n",
       "       [ 1.51475978e+01],\n",
       "       [ 5.29862608e+00],\n",
       "       [ 1.74456613e+01],\n",
       "       [ 2.25450535e+01],\n",
       "       [ 2.97014522e+01],\n",
       "       [ 2.17642932e+01],\n",
       "       [ 3.59941733e+01],\n",
       "       [ 1.55566905e+01],\n",
       "       [ 4.04107624e+01],\n",
       "       [ 3.69795729e+01],\n",
       "       [ 1.31884187e+01],\n",
       "       [ 1.79928629e+01],\n",
       "       [ 1.94983869e+01],\n",
       "       [ 2.68946684e+01],\n",
       "       [ 3.31463575e+00],\n",
       "       [ 3.89543794e+01],\n",
       "       [ 2.72531619e+01],\n",
       "       [ 2.98082065e+01],\n",
       "       [ 1.06969965e+01],\n",
       "       [ 2.22942100e+01],\n",
       "       [ 1.87077705e+01],\n",
       "       [ 1.98000244e+01],\n",
       "       [ 2.07089294e+01],\n",
       "       [ 1.51387124e+01],\n",
       "       [ 2.00527039e+01],\n",
       "       [ 2.07980922e+01],\n",
       "       [ 3.57842034e+01],\n",
       "       [ 1.69285973e+01],\n",
       "       [ 2.71811335e+00],\n",
       "       [ 5.18057507e+01],\n",
       "       [ 2.90007811e+01],\n",
       "       [ 1.44046775e+01],\n",
       "       [ 3.04038061e+01],\n",
       "       [ 1.89401053e+01],\n",
       "       [ 2.62358388e+01],\n",
       "       [ 2.59822307e+01],\n",
       "       [ 1.63387403e+01],\n",
       "       [ 3.85689618e+01],\n",
       "       [ 2.92848583e+01],\n",
       "       [ 3.16751538e+01],\n",
       "       [ 2.04159200e+01],\n",
       "       [ 1.33954072e+01],\n",
       "       [ 2.41237949e+01],\n",
       "       [ 3.58899179e+01],\n",
       "       [ 4.08335862e+01],\n",
       "       [ 2.59649793e+01],\n",
       "       [ 2.23990272e+01],\n",
       "       [ 9.09078328e+00],\n",
       "       [ 2.20852564e+01],\n",
       "       [ 7.71838324e+00],\n",
       "       [ 1.32711191e+01],\n",
       "       [ 1.81737772e+00],\n",
       "       [ 2.08712953e+01],\n",
       "       [ 1.10374560e+01],\n",
       "       [ 1.64643788e+01],\n",
       "       [ 2.69606554e+01],\n",
       "       [ 6.26087077e+00],\n",
       "       [ 3.56296103e+01],\n",
       "       [ 2.38124087e+01],\n",
       "       [ 1.75438560e+01],\n",
       "       [ 2.02074186e+01],\n",
       "       [ 2.84958519e+01],\n",
       "       [ 9.26584979e+00],\n",
       "       [ 4.11789069e+01],\n",
       "       [ 1.42941608e+01],\n",
       "       [ 2.08854476e+01],\n",
       "       [ 3.19356864e+01],\n",
       "       [ 3.10899076e+01],\n",
       "       [ 9.60774098e+00],\n",
       "       [ 1.15856169e+01],\n",
       "       [ 1.20217901e+01],\n",
       "       [ 5.21313684e+00],\n",
       "       [ 2.68444500e+01],\n",
       "       [ 5.16304077e+01],\n",
       "       [ 2.13064871e+01],\n",
       "       [ 4.74105337e+01],\n",
       "       [ 4.23611268e+01],\n",
       "       [ 3.48475733e+01],\n",
       "       [ 4.21866410e+01],\n",
       "       [ 3.24389943e+01],\n",
       "       [ 3.17712819e+01],\n",
       "       [ 3.64690539e+01],\n",
       "       [ 1.76028426e+01],\n",
       "       [ 2.39221725e+01],\n",
       "       [ 1.46175890e+01],\n",
       "       [ 7.85141735e+00],\n",
       "       [ 2.14613667e+01],\n",
       "       [ 1.17774789e+01],\n",
       "       [ 3.28014832e+01],\n",
       "       [ 4.06361172e+01],\n",
       "       [ 7.33134453e+00],\n",
       "       [ 8.87719432e+00],\n",
       "       [ 6.24986843e+00],\n",
       "       [ 2.31659178e+00],\n",
       "       [ 2.58619116e+01],\n",
       "       [ 3.67700283e+01],\n",
       "       [ 2.17941783e+01],\n",
       "       [ 1.75965256e+01],\n",
       "       [ 1.24632910e+01],\n",
       "       [ 2.39386481e+01],\n",
       "       [ 3.47264619e+01],\n",
       "       [ 2.46954600e+01],\n",
       "       [ 5.71300280e+00],\n",
       "       [ 5.46424011e+01],\n",
       "       [ 8.09388220e+00],\n",
       "       [ 7.25316911e+00],\n",
       "       [ 1.21272294e+01],\n",
       "       [ 2.47004475e+01],\n",
       "       [ 1.04179308e+01],\n",
       "       [ 3.38718537e+01],\n",
       "       [ 1.78006546e+01],\n",
       "       [ 2.26690660e+01],\n",
       "       [ 3.92617735e+01],\n",
       "       [ 3.96816760e+00],\n",
       "       [ 4.93295735e+01],\n",
       "       [ 2.10558027e+01],\n",
       "       [ 2.71586851e+01],\n",
       "       [ 2.59629188e+01],\n",
       "       [ 6.78123749e+01],\n",
       "       [ 1.02650628e+01],\n",
       "       [ 2.39545611e+01],\n",
       "       [ 1.23885426e+01],\n",
       "       [ 9.20120180e+00],\n",
       "       [ 2.70119373e+01],\n",
       "       [ 2.50026550e+01],\n",
       "       [ 7.30520758e+00],\n",
       "       [ 7.89732321e+00],\n",
       "       [ 1.93976410e+01],\n",
       "       [ 1.52238525e+01],\n",
       "       [ 3.09569591e+01],\n",
       "       [ 5.25753236e+01],\n",
       "       [ 3.23348564e+01],\n",
       "       [ 2.62275218e+01],\n",
       "       [ 9.72613354e+00],\n",
       "       [ 1.23773494e+01],\n",
       "       [ 2.50175534e+01],\n",
       "       [ 1.74233731e+01],\n",
       "       [ 2.37629284e+01],\n",
       "       [ 2.95530821e+01],\n",
       "       [ 2.40701045e+01],\n",
       "       [ 3.72497455e+01],\n",
       "       [ 2.67009499e+01],\n",
       "       [ 1.88087727e+01],\n",
       "       [ 1.57418181e+01],\n",
       "       [ 2.84937509e+01],\n",
       "       [ 2.86490664e+01],\n",
       "       [ 1.81851264e+01],\n",
       "       [ 3.89335858e+01],\n",
       "       [ 4.54193936e+01],\n",
       "       [ 3.59070063e+01],\n",
       "       [ 3.37512876e+01],\n",
       "       [ 4.16653279e+01],\n",
       "       [ 2.95587514e+01],\n",
       "       [ 1.09502319e+01],\n",
       "       [ 4.08013717e+01],\n",
       "       [ 1.18063981e+01],\n",
       "       [ 3.17119047e+00],\n",
       "       [ 1.95842484e+01],\n",
       "       [ 5.76014022e+00],\n",
       "       [ 3.78218268e+01],\n",
       "       [ 1.38784206e+01],\n",
       "       [ 1.07903696e+01],\n",
       "       [ 2.42595040e+01],\n",
       "       [ 3.89115660e+01],\n",
       "       [ 1.94626521e+01],\n",
       "       [ 1.57523793e+01],\n",
       "       [ 2.97324334e+01],\n",
       "       [ 3.45068478e+01],\n",
       "       [ 2.28066147e+01],\n",
       "       [ 1.84575143e+01],\n",
       "       [ 2.37897593e+01],\n",
       "       [ 3.79066574e+01],\n",
       "       [ 2.11017909e+01],\n",
       "       [ 4.32391728e+01],\n",
       "       [ 1.07934065e+01],\n",
       "       [ 1.68002197e+01],\n",
       "       [ 8.84518341e+00],\n",
       "       [ 2.50773899e+01],\n",
       "       [ 7.75849622e+00],\n",
       "       [ 3.07121404e+00],\n",
       "       [ 3.98024408e+01],\n",
       "       [ 3.41638712e+01],\n",
       "       [ 5.05916302e+00],\n",
       "       [ 1.98245087e+01],\n",
       "       [ 2.39303613e+01],\n",
       "       [ 2.26916867e+01],\n",
       "       [ 1.66671931e+01],\n",
       "       [ 1.89503472e+01],\n",
       "       [ 9.61002140e+00],\n",
       "       [ 2.53845148e+01],\n",
       "       [ 8.96833381e+00],\n",
       "       [ 4.77801955e+00],\n",
       "       [ 1.07303805e+01],\n",
       "       [ 3.17137211e+01],\n",
       "       [ 3.80028068e+01],\n",
       "       [ 1.35698942e+01],\n",
       "       [ 1.42847751e+01],\n",
       "       [ 2.32872892e+01],\n",
       "       [ 3.64051232e+01],\n",
       "       [ 1.19401606e+01],\n",
       "       [ 1.22939171e+01],\n",
       "       [-1.43558757e+01],\n",
       "       [ 3.27384349e+01],\n",
       "       [ 4.95862098e+01],\n",
       "       [ 3.23506605e+01],\n",
       "       [ 2.21188342e+01],\n",
       "       [ 5.68274606e+00],\n",
       "       [ 2.13033293e+01],\n",
       "       [-2.46072822e+00],\n",
       "       [ 2.31638791e+01],\n",
       "       [ 6.64927447e+00],\n",
       "       [ 3.52926443e+01],\n",
       "       [ 9.09363960e+00],\n",
       "       [ 1.36164380e+01],\n",
       "       [ 2.35319932e+01],\n",
       "       [ 2.71134892e+01],\n",
       "       [ 1.23193892e+01],\n",
       "       [ 2.79115439e+01],\n",
       "       [ 1.30840142e+01],\n",
       "       [ 4.56165943e+00],\n",
       "       [ 2.29812007e+01],\n",
       "       [ 4.09342880e+01],\n",
       "       [ 3.32215301e+01],\n",
       "       [ 2.73606841e+00],\n",
       "       [ 1.61081561e+01],\n",
       "       [ 6.20618841e+01],\n",
       "       [ 2.61362641e+01],\n",
       "       [ 2.78515284e+01],\n",
       "       [ 4.21863199e+00],\n",
       "       [ 1.24379622e+01],\n",
       "       [ 2.41938394e+01],\n",
       "       [ 2.44614998e+01],\n",
       "       [ 2.72448585e+01],\n",
       "       [-5.42635189e+01],\n",
       "       [ 2.00613629e+01],\n",
       "       [ 3.75954107e+01],\n",
       "       [ 2.80504238e+01],\n",
       "       [ 3.44752800e+01],\n",
       "       [ 1.17373002e+01],\n",
       "       [ 3.46349598e+01],\n",
       "       [ 1.14299125e+01],\n",
       "       [ 4.14178677e+01],\n",
       "       [ 2.47874317e+01],\n",
       "       [ 2.97496804e+01],\n",
       "       [ 1.08236343e+01],\n",
       "       [ 2.77309889e+01],\n",
       "       [ 1.07234883e+01],\n",
       "       [ 1.27458115e+01],\n",
       "       [ 2.87365108e+01],\n",
       "       [ 3.64821027e+01],\n",
       "       [ 3.26940106e+01],\n",
       "       [ 1.04123509e+01],\n",
       "       [-2.86680067e+00],\n",
       "       [ 1.95380610e+01],\n",
       "       [ 1.58547821e+00],\n",
       "       [ 3.65263625e+01],\n",
       "       [ 2.85558517e+01],\n",
       "       [ 3.54597227e+01],\n",
       "       [ 1.02244843e+01],\n",
       "       [ 2.56038325e+01],\n",
       "       [ 1.30989885e+01],\n",
       "       [ 1.45862650e+01],\n",
       "       [ 2.95959957e+01],\n",
       "       [ 1.55975831e+01],\n",
       "       [ 2.31858131e+01],\n",
       "       [ 8.25029449e+00],\n",
       "       [ 7.48877733e+00],\n",
       "       [ 3.72671579e+01],\n",
       "       [ 1.25372706e+01]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.predict(X_diab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# alg = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Input(10),\n",
    "#     tf.keras.layers.Dense(20, activation='relu'),\n",
    "#     tf.keras.layers.Dense(1, activation='relu'),\n",
    "# ])\n",
    "\n",
    "# alg.compile(optimizer='adam', loss='mse', )\n",
    "\n",
    "# alg.fit(X_diab, y_diab, epochs=1000, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alg.predict(X_diab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
